{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a735ee1",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03418de",
   "metadata": {},
   "source": [
    "In this notebook we evaluate the accuracy of the predicted alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67636de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a85da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from plotnine import *\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6c602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'train' # 'test'\n",
    "VERSION = 'toy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5564e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_ROOT = Path('../ttmp/Chopin_Mazurkas_Modified/annotations_beat')\n",
    "query_list = Path(f'cfg_files/queries.{DATASET}.{VERSION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70369f24",
   "metadata": {},
   "source": [
    "### Evaluate hypothesis directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0ed995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dir(hypdir, querylist, annot_root_1, annot_root_2, hop_sec, savefile = None):\n",
    "    allErrs = {}\n",
    "    cnt = 0\n",
    "    print(f'Processing {hypdir} ', end='')\n",
    "    with open(querylist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            assert len(parts) == 2\n",
    "            basename = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            hypfile = hypdir + '/' + basename + '.pkl'\n",
    "            if not os.path.exists(hypfile):\n",
    "                print(\"X\", end='')\n",
    "                continue\n",
    "            err = eval_file(hypfile, annot_root_1, annot_root_2, hop_sec)\n",
    "            if err is not None:\n",
    "                allErrs[basename] = err\n",
    "            cnt += 1\n",
    "            if cnt % 500 == 0:\n",
    "                print(\".\", end='')\n",
    "    print(' done')\n",
    "    if savefile:\n",
    "        pickle.dump(allErrs, open(savefile, 'wb'))\n",
    "        \n",
    "    return allErrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9147908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_file(hypfile, annot_root_1, annot_root_2, hop_sec):\n",
    "    parts = os.path.basename(hypfile).split('__')\n",
    "    assert len(parts) == 2\n",
    "    piece = extractPieceName(parts[0])\n",
    "    annotfile1 = (annot_root_1 / piece / parts[0]).with_suffix('.beat')\n",
    "    annotfile2 = (annot_root_2 / piece / parts[1]).with_suffix('.beat')\n",
    "    \n",
    "    # if groundtruth annotation files are empty, skip this hypothesis file\n",
    "    try:\n",
    "        gt1, gt2 = getTimestamps(annotfile1, annotfile2)\n",
    "        hypalign = loadAlignment(hypfile) # warping path in frames\n",
    "    except:\n",
    "        print(f'Skipping hypothesis file {hypfile}')\n",
    "        return None\n",
    "\n",
    "    if hypalign is None:\n",
    "        err = np.array(np.ones(gt1.shape) * np.inf)\n",
    "    else:\n",
    "        pred2 = np.interp(gt1, hypalign[0,:]*hop_sec, hypalign[1,:]*hop_sec)\n",
    "        err = pred2 - gt2\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c6c323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPieceName(fullpath):\n",
    "    basename = os.path.basename(fullpath) # e.g. Chopin_Op068No3_Sztompka-1959_pid9170b-21\n",
    "    parts = basename.split('_')\n",
    "    piece = '_'.join(parts[0:2]) # e.g. Chopin_Op068No3\n",
    "    return piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcecc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimestamps(annotfile1, annotfile2):\n",
    "    df1 = pd.read_csv(annotfile1, header=None, sep='\\s+', skiprows=3) \n",
    "    df2 = pd.read_csv(annotfile2, header=None, sep='\\s+', skiprows=3)\n",
    "\n",
    "    df_merged = pd.merge(df1, df2, on=[2], how='inner')\n",
    "    df_merged = df_merged[df_merged[2].astype(str).str.match(\".*\\d$\")]\n",
    "\n",
    "    return df_merged['0_x'], df_merged['0_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db299879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAlignment(hypfile):\n",
    "    with open(hypfile, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3accbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_dirs(rootdir, querylist, hop_sec, outdir, system, benchmark):\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    if benchmark == 'partialOverlap':\n",
    "        annot_root_1 = Path(f'../ttmp/Chopin_Mazurkas_Benchmarks/partialStart/annotations_beat')\n",
    "        annot_root_2 = Path(f'../ttmp/Chopin_Mazurkas_Benchmarks/partialEnd/annotations_beat')\n",
    "    elif 'prepost' in benchmark:\n",
    "        sec = benchmark.split('_')[-1]\n",
    "        annot_root_1 = Path(f'../ttmp/Chopin_Mazurkas_Benchmarks/pre_{sec}/annotations_beat')\n",
    "        annot_root_2 = Path(f'../ttmp/Chopin_Mazurkas_Benchmarks/post_{sec}/annotations_beat')\n",
    "    elif benchmark == 'matching':\n",
    "        annot_root_1 = Path(f'../ttmp/Chopin_Mazurkas_Modified/annotations_beat')\n",
    "        annot_root_2 = Path(f'../ttmp/Chopin_Mazurkas_Modified/annotations_beat')\n",
    "    else:\n",
    "        annot_root_1 = Path(f'../ttmp/Chopin_Mazurkas_Benchmarks/{benchmark}/annotations_beat')\n",
    "        annot_root_2 = Path(f'../ttmp/Chopin_Mazurkas_Modified/annotations_beat')\n",
    "    for hypdir in glob.glob(f'{rootdir}/{benchmark}/{system}'):\n",
    "        outpath = outdir + '/' + f'{benchmark}'\n",
    "        Path(outpath).mkdir(parents=True, exist_ok=True)\n",
    "        savefile = outpath + '/' + os.path.basename(hypdir) + '.pkl'\n",
    "        allErrs = eval_dir(hypdir, querylist, annot_root_1, annot_root_2, hop_sec, savefile = savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1f935",
   "metadata": {},
   "source": [
    "**Evaluate on Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f37403ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_ROOT = f'experiments_{DATASET}/{VERSION}'\n",
    "hop_sec = 512 * 1 / 22050\n",
    "outdir = f'evaluations_{DATASET}/{VERSION}'\n",
    "Path(outdir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abfed7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_benchmark(experiments_root, hop_sec, outdir, system, benchmark):\n",
    "    eval_all_dirs(EXPERIMENTS_ROOT, query_list, hop_sec, outdir, system, benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a897469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEMS = ['DTW1', 'DTW2', 'DTW3', 'SubseqDTW1', 'SubseqDTW2', 'SubseqDTW3', 'NWTW', 'FlexDTW']\n",
    "BENCHMARKS = ['Matching', 'Subseq_20', 'Subseq_30', 'Subseq_40', 'PartialStart', 'PartialEnd', 'PartialOverlap', \n",
    "              'Pre_5', 'Pre_10', 'Pre_20', 'Post_5', 'Post_10', 'Post_20', 'PrePost_5', \n",
    "              'PrePost_10', 'PrePost_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57e706de",
   "metadata": {},
   "outputs": [],
   "source": [
    "systems = [system.lower() for system in SYSTEMS]\n",
    "benchmarks = []\n",
    "for benchmark in BENCHMARKS:\n",
    "    if benchmark == 'PartialOverlap':\n",
    "        benchmarks.append('partialOverlap')\n",
    "    elif benchmark == 'PartialStart':\n",
    "        benchmarks.append('partialStart')\n",
    "    elif benchmark == 'PartialEnd':\n",
    "        benchmarks.append('partialEnd')\n",
    "    elif 'PrePost' in benchmark:\n",
    "        sec = benchmark.split('_')[-1]\n",
    "        benchmarks.append(f'prepost_{sec}')\n",
    "    else:\n",
    "        benchmarks.append(benchmark.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb3cf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_benchmarks(experiments_root, hop_sec, outdir, systems, benchmarks):\n",
    "    for benchmark in benchmarks:\n",
    "        for system in systems:\n",
    "            eval_benchmark(experiments_root, hop_sec, outdir, system, benchmark)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "488d9d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiments_train/toy/matching/dtw1  done\n",
      "Processing experiments_train/toy/matching/dtw2  done\n",
      "Processing experiments_train/toy/matching/dtw3  done\n",
      "Processing experiments_train/toy/matching/subseqdtw1  done\n",
      "Processing experiments_train/toy/matching/subseqdtw2  done\n",
      "Processing experiments_train/toy/matching/subseqdtw3  done\n",
      "Processing experiments_train/toy/matching/nwtw  done\n",
      "Processing experiments_train/toy/matching/flexdtw  done\n",
      "Processing experiments_train/toy/subseq_20/dtw1  done\n",
      "Processing experiments_train/toy/subseq_20/dtw2  done\n",
      "Processing experiments_train/toy/subseq_20/dtw3  done\n",
      "Processing experiments_train/toy/subseq_20/subseqdtw1  done\n",
      "Processing experiments_train/toy/subseq_20/subseqdtw2  done\n",
      "Processing experiments_train/toy/subseq_20/subseqdtw3  done\n",
      "Processing experiments_train/toy/subseq_20/nwtw  done\n",
      "Processing experiments_train/toy/subseq_20/flexdtw  done\n",
      "Processing experiments_train/toy/subseq_30/dtw1  done\n",
      "Processing experiments_train/toy/subseq_30/dtw2  done\n",
      "Processing experiments_train/toy/subseq_30/dtw3  done\n",
      "Processing experiments_train/toy/subseq_30/subseqdtw1  done\n",
      "Processing experiments_train/toy/subseq_30/subseqdtw2  done\n",
      "Processing experiments_train/toy/subseq_30/subseqdtw3  done\n",
      "Processing experiments_train/toy/subseq_30/nwtw  done\n",
      "Processing experiments_train/toy/subseq_30/flexdtw  done\n",
      "Processing experiments_train/toy/subseq_40/dtw1  done\n",
      "Processing experiments_train/toy/subseq_40/dtw2  done\n",
      "Processing experiments_train/toy/subseq_40/dtw3  done\n",
      "Processing experiments_train/toy/subseq_40/subseqdtw1  done\n",
      "Processing experiments_train/toy/subseq_40/subseqdtw2  done\n",
      "Processing experiments_train/toy/subseq_40/subseqdtw3  done\n",
      "Processing experiments_train/toy/subseq_40/nwtw  done\n",
      "Processing experiments_train/toy/subseq_40/flexdtw  done\n",
      "Processing experiments_train/toy/partialStart/dtw1  done\n",
      "Processing experiments_train/toy/partialStart/dtw2  done\n",
      "Processing experiments_train/toy/partialStart/dtw3  done\n",
      "Processing experiments_train/toy/partialStart/subseqdtw1  done\n",
      "Processing experiments_train/toy/partialStart/subseqdtw2  done\n",
      "Processing experiments_train/toy/partialStart/subseqdtw3  done\n",
      "Processing experiments_train/toy/partialStart/nwtw  done\n",
      "Processing experiments_train/toy/partialStart/flexdtw  done\n",
      "Processing experiments_train/toy/partialEnd/dtw1  done\n",
      "Processing experiments_train/toy/partialEnd/dtw2  done\n",
      "Processing experiments_train/toy/partialEnd/dtw3  done\n",
      "Processing experiments_train/toy/partialEnd/subseqdtw1  done\n",
      "Processing experiments_train/toy/partialEnd/subseqdtw2  done\n",
      "Processing experiments_train/toy/partialEnd/subseqdtw3  done\n",
      "Processing experiments_train/toy/partialEnd/nwtw  done\n",
      "Processing experiments_train/toy/partialEnd/flexdtw  done\n",
      "Processing experiments_train/toy/partialOverlap/dtw1  done\n",
      "Processing experiments_train/toy/partialOverlap/dtw2  done\n",
      "Processing experiments_train/toy/partialOverlap/dtw3  done\n",
      "Processing experiments_train/toy/partialOverlap/subseqdtw1  done\n",
      "Processing experiments_train/toy/partialOverlap/subseqdtw2  done\n",
      "Processing experiments_train/toy/partialOverlap/subseqdtw3  done\n",
      "Processing experiments_train/toy/partialOverlap/nwtw  done\n",
      "Processing experiments_train/toy/partialOverlap/flexdtw  done\n",
      "Processing experiments_train/toy/pre_5/dtw1  done\n",
      "Processing experiments_train/toy/pre_5/dtw2  done\n",
      "Processing experiments_train/toy/pre_5/dtw3  done\n",
      "Processing experiments_train/toy/pre_5/subseqdtw1  done\n",
      "Processing experiments_train/toy/pre_5/subseqdtw2  done\n",
      "Processing experiments_train/toy/pre_5/subseqdtw3  done\n",
      "Processing experiments_train/toy/pre_5/nwtw  done\n",
      "Processing experiments_train/toy/pre_5/flexdtw  done\n",
      "Processing experiments_train/toy/pre_10/dtw1  done\n",
      "Processing experiments_train/toy/pre_10/dtw2  done\n",
      "Processing experiments_train/toy/pre_10/dtw3  done\n",
      "Processing experiments_train/toy/pre_10/subseqdtw1  done\n",
      "Processing experiments_train/toy/pre_10/subseqdtw2  done\n",
      "Processing experiments_train/toy/pre_10/subseqdtw3  done\n",
      "Processing experiments_train/toy/pre_10/nwtw  done\n",
      "Processing experiments_train/toy/pre_10/flexdtw  done\n",
      "Processing experiments_train/toy/pre_20/dtw1  done\n",
      "Processing experiments_train/toy/pre_20/dtw2  done\n",
      "Processing experiments_train/toy/pre_20/dtw3  done\n",
      "Processing experiments_train/toy/pre_20/subseqdtw1  done\n",
      "Processing experiments_train/toy/pre_20/subseqdtw2  done\n",
      "Processing experiments_train/toy/pre_20/subseqdtw3  done\n",
      "Processing experiments_train/toy/pre_20/nwtw  done\n",
      "Processing experiments_train/toy/pre_20/flexdtw  done\n",
      "Processing experiments_train/toy/post_5/dtw1  done\n",
      "Processing experiments_train/toy/post_5/dtw2  done\n",
      "Processing experiments_train/toy/post_5/dtw3  done\n",
      "Processing experiments_train/toy/post_5/subseqdtw1  done\n",
      "Processing experiments_train/toy/post_5/subseqdtw2  done\n",
      "Processing experiments_train/toy/post_5/subseqdtw3  done\n",
      "Processing experiments_train/toy/post_5/nwtw  done\n",
      "Processing experiments_train/toy/post_5/flexdtw  done\n",
      "Processing experiments_train/toy/post_10/dtw1  done\n",
      "Processing experiments_train/toy/post_10/dtw2  done\n",
      "Processing experiments_train/toy/post_10/dtw3  done\n",
      "Processing experiments_train/toy/post_10/subseqdtw1  done\n",
      "Processing experiments_train/toy/post_10/subseqdtw2  done\n",
      "Processing experiments_train/toy/post_10/subseqdtw3  done\n",
      "Processing experiments_train/toy/post_10/nwtw  done\n",
      "Processing experiments_train/toy/post_10/flexdtw  done\n",
      "Processing experiments_train/toy/post_20/dtw1  done\n",
      "Processing experiments_train/toy/post_20/dtw2  done\n",
      "Processing experiments_train/toy/post_20/dtw3  done\n",
      "Processing experiments_train/toy/post_20/subseqdtw1  done\n",
      "Processing experiments_train/toy/post_20/subseqdtw2  done\n",
      "Processing experiments_train/toy/post_20/subseqdtw3  done\n",
      "Processing experiments_train/toy/post_20/nwtw  done\n",
      "Processing experiments_train/toy/post_20/flexdtw  done\n",
      "Processing experiments_train/toy/prepost_5/dtw1  done\n",
      "Processing experiments_train/toy/prepost_5/dtw2  done\n",
      "Processing experiments_train/toy/prepost_5/dtw3  done\n",
      "Processing experiments_train/toy/prepost_5/subseqdtw1  done\n",
      "Processing experiments_train/toy/prepost_5/subseqdtw2  done\n",
      "Processing experiments_train/toy/prepost_5/subseqdtw3  done\n",
      "Processing experiments_train/toy/prepost_5/nwtw  done\n",
      "Processing experiments_train/toy/prepost_5/flexdtw  done\n",
      "Processing experiments_train/toy/prepost_10/dtw1  done\n",
      "Processing experiments_train/toy/prepost_10/dtw2  done\n",
      "Processing experiments_train/toy/prepost_10/dtw3  done\n",
      "Processing experiments_train/toy/prepost_10/subseqdtw1  done\n",
      "Processing experiments_train/toy/prepost_10/subseqdtw2  done\n",
      "Processing experiments_train/toy/prepost_10/subseqdtw3  done\n",
      "Processing experiments_train/toy/prepost_10/nwtw  done\n",
      "Processing experiments_train/toy/prepost_10/flexdtw  done\n",
      "Processing experiments_train/toy/prepost_20/dtw1  done\n",
      "Processing experiments_train/toy/prepost_20/dtw2  done\n",
      "Processing experiments_train/toy/prepost_20/dtw3  done\n",
      "Processing experiments_train/toy/prepost_20/subseqdtw1  done\n",
      "Processing experiments_train/toy/prepost_20/subseqdtw2  done\n",
      "Processing experiments_train/toy/prepost_20/subseqdtw3  done\n",
      "Processing experiments_train/toy/prepost_20/nwtw  done\n",
      "Processing experiments_train/toy/prepost_20/flexdtw  done\n"
     ]
    }
   ],
   "source": [
    "eval_all_benchmarks(EXPERIMENTS_ROOT, hop_sec, outdir, systems, benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d80ae3",
   "metadata": {},
   "source": [
    "### Plot error vs tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60e3c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error_rates(errFile, maxTol):\n",
    "    \n",
    "    # read from file\n",
    "    with open(errFile, 'rb') as f:\n",
    "        allErrs = pickle.load(f)\n",
    "    \n",
    "    # collect all errors\n",
    "    errsFlat = []\n",
    "    for query in allErrs:\n",
    "        errs = np.array(allErrs[query])\n",
    "        errsFlat.append(errs)\n",
    "    errsFlat = np.concatenate(errsFlat)\n",
    "    \n",
    "    # calculate error rates\n",
    "    errRates = np.zeros(maxTol+1)\n",
    "    for i in range(maxTol+1):\n",
    "        errRates[i] = np.mean(np.abs(errsFlat) > i/1000)\n",
    "    \n",
    "    return errRates, errsFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3577174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error_rates_batch(indir, basenames, maxTol):\n",
    "    errRates = np.zeros((len(basenames), maxTol+1))\n",
    "    allErrVals = []\n",
    "    print('Computing error rates ', end='')\n",
    "    for i, basename in enumerate(basenames):\n",
    "        errFile = indir + '/' + basename + '.pkl'\n",
    "        errRates[i,:], errors = calc_error_rates(errFile, maxTol)\n",
    "        allErrVals.append(errors)\n",
    "        print('.', end='')\n",
    "    print(' done')\n",
    "    return errRates, allErrVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "961fd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_roc(errRates, basenames):\n",
    "    numSystems = errRates.shape[0]\n",
    "    maxTol = errRates.shape[1] - 1\n",
    "    for i in range(numSystems):\n",
    "        plt.plot(np.arange(maxTol+1), errRates[i,:] * 100.0)\n",
    "    plt.legend(basenames, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel('Error Tolerance (ms)')\n",
    "    plt.ylabel('Error Rate (%)')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1bf0e",
   "metadata": {},
   "source": [
    "**Evaluate on Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04332674",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_ROOT_DIR = f'evaluations_{DATASET}/{VERSION}'\n",
    "toPlot = []\n",
    "\n",
    "for benchmark in benchmarks:\n",
    "    for system in systems:\n",
    "        toPlot.append(f'{benchmark}/{system}')\n",
    "maxTol = 1000 # in msec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5488915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errs(eval_root_dir, toPlot, maxTol):\n",
    "    errRates, errVals = calc_error_rates_batch(EVAL_ROOT_DIR, toPlot, maxTol)\n",
    "    return errRates, errVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b760871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing error rates ................................................................................................................................ done\n"
     ]
    }
   ],
   "source": [
    "errRates, errVals = get_errs(EVAL_ROOT_DIR, toPlot, maxTol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88bffa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRates.shape[0] == len(SYSTEMS) * len(BENCHMARKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a233a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'evaluations_{DATASET}/{VERSION}_errRates', errRates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73e58e",
   "metadata": {},
   "source": [
    "### Make Plots (New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b945fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(time, errRates):\n",
    "    data = {}\n",
    "    \n",
    "    num_systems = len(SYSTEMS)\n",
    "    num_benchmarks = len(BENCHMARKS)\n",
    "    \n",
    "    data['Benchmark'] = []\n",
    "    for benchmark in BENCHMARKS:\n",
    "        data['Benchmark'] += [benchmark] * num_systems\n",
    "    \n",
    "    data['System'] = [system for system in SYSTEMS] * num_benchmarks\n",
    "\n",
    "    data['Error'] = []\n",
    "    for i in range(num_benchmarks*num_systems):\n",
    "            data['Error'].append(errRates[i][time]*100)\n",
    "            \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    benchmark_categories = CategoricalDtype(categories=BENCHMARKS, ordered=True)\n",
    "    df.Benchmark = df.Benchmark.astype(benchmark_categories)\n",
    "    system_categories = CategoricalDtype(categories=SYSTEMS, ordered=True)\n",
    "    df.System = df.System.astype(system_categories)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcb8a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRates = np.load(f'evaluations_{DATASET}/{VERSION}_errRates.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd69c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rates at 200ms tolerance\n",
    "ms200_df = make_df(200, errRates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e0df3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rates at 100ms and 500ms tolerance (black horizontal bars on plot)\n",
    "ms100_df = make_df(100, errRates)\n",
    "ms500_df = make_df(500, errRates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdcb4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#620FA2', '#874CB4', '#A77DC4', '#0C7715', '#229E25', '#3AC738', '#FF0000', '#16418F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4f4388e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibukey/anaconda3/envs/mir/lib/python3.7/site-packages/plotnine/ggplot.py:721: PlotnineWarning: Saving 18 x 5 in image.\n",
      "/home/ibukey/anaconda3/envs/mir/lib/python3.7/site-packages/plotnine/ggplot.py:722: PlotnineWarning: Filename: evaluations_train/toy_plot.png\n"
     ]
    }
   ],
   "source": [
    "(ggplot(ms200_df, aes(x=\"System\", y=\"Error\", fill=\"System\")) +\n",
    "    geom_bar(width = 0.7, position=position_dodge2(preserve='single', width=0.2), stat='identity') +\n",
    "    scale_y_continuous(expand = [0, 0], limits = [0, 100]) +\n",
    "    scale_fill_manual(values=colors) +\n",
    "    geom_crossbar(ms100_df, aes(ymin=\"Error\", ymax=\"Error\")) +\n",
    "    geom_crossbar(ms500_df, aes(ymin=\"Error\", ymax=\"Error\")) +\n",
    "    facet_grid('. ~ Benchmark') +\n",
    "    theme_bw() + \n",
    "    labs(y = \"Error Rate (%)\") +\n",
    "    theme(dpi=300, legend_position=(0.5, -0.07), legend_direction=\"horizontal\", legend_box = \"horizontal\", legend_title_align='bottom', \n",
    "            legend_background = element_blank(),\n",
    "            legend_title = element_text(size=10),\n",
    "            strip_background = element_blank(),\n",
    "            strip_text_x = element_text(angle = 50, size=7, position=(0.3, -0.08)),\n",
    "            axis_text_x = element_blank(),\n",
    "            axis_ticks_major_x = element_blank(),\n",
    "            axis_text_y = element_text(size = 10, colour='black'), \n",
    "            axis_title_x = element_blank(),\n",
    "            axis_title_y = element_text(size = 10, margin={'r': 6.0})) +\n",
    "    guides(fill=guide_legend(nrow=1,byrow=True, title=\"\", title_position='left', label_position=\"right\", override_aes = {'size': 0})))\n",
    "# .save(f'evaluations_{DATASET}/{VERSION}_plot.png', width=18, height=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad37c58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c11bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
